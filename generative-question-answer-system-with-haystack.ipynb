{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":7598019,"sourceType":"datasetVersion","datasetId":4422805},{"sourceId":7614152,"sourceType":"datasetVersion","datasetId":4434106},{"sourceId":7782267,"sourceType":"datasetVersion","datasetId":4554256}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tarekyahia/generative-question-answer-system-with-haystack?scriptVersionId=168285325\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"### besmi allah","metadata":{}},{"cell_type":"markdown","source":"## Libraries ","metadata":{}},{"cell_type":"code","source":"# install haystack\n!pip install --upgrade pip\n\n!pip install \\\npeft \\\nevaluate==0.4.0 \\\nrouge_score==0.1.2 \\\n\n!pip install 'farm-haystack[all]' ## or 'all-gpu' for the GPU-enabled dependencies\n","metadata":{"execution":{"iopub.status.busy":"2024-03-07T07:31:20.338425Z","iopub.execute_input":"2024-03-07T07:31:20.340569Z","iopub.status.idle":"2024-03-07T07:34:40.598236Z","shell.execute_reply.started":"2024-03-07T07:31:20.340514Z","shell.execute_reply":"2024-03-07T07:34:40.596746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd\nimport re\n\n\nfrom haystack.utils import convert_files_to_docs\nfrom haystack.nodes import PreProcessor\nfrom haystack.nodes import PromptNode, PromptTemplate, AnswerParser\nfrom haystack.document_stores import FAISSDocumentStore\nfrom haystack.nodes import EmbeddingRetriever\nfrom haystack.pipelines import Pipeline\nfrom haystack.nodes.sampler import TopPSampler\nfrom haystack.nodes.ranker import LostInTheMiddleRanker\n\nfrom evaluate import load\nmetric = load(\"rouge\")\n\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainer,AutoTokenizer\nimport torch\nfrom peft import PeftModel, PeftConfig\n\n\nimport logging\n\nlogging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\nlogging.getLogger(\"haystack\").setLevel(logging.INFO)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-07T07:34:40.600158Z","iopub.execute_input":"2024-03-07T07:34:40.600523Z","iopub.status.idle":"2024-03-07T07:35:20.078042Z","shell.execute_reply.started":"2024-03-07T07:34:40.60049Z","shell.execute_reply":"2024-03-07T07:35:20.076745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Knowledge Base :","metadata":{}},{"cell_type":"code","source":"\nBOOK_DIR = '/kaggle/input/mlbookspdfs' # to the books\n\n# show the books \nfor dirname, _, filenames in os.walk(BOOK_DIR):\n    print('-------------------------------------------')\n    for filename in filenames:\n        print(filename)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T07:35:20.079752Z","iopub.execute_input":"2024-03-07T07:35:20.080151Z","iopub.status.idle":"2024-03-07T07:35:20.092568Z","shell.execute_reply.started":"2024-03-07T07:35:20.080118Z","shell.execute_reply":"2024-03-07T07:35:20.09052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"markdown","source":"- PDFs to TXT and cleaning","metadata":{}},{"cell_type":"code","source":"def clean_text(text: str) -> str:\n    \"\"\"\n    \n   Note: The source code for the function is a combination of clean_wiki_text (available in haystack) and some custom cleanup.\n   \n    \"\"\"\n    # get rid of multiple new lines\n    while \"\\n\\n\" in text:\n        text = text.replace(\"\\n\\n\", \"\\n\")\n\n    # remove extremely short lines\n    lines = text.split(\"\\n\")\n    cleaned = []\n    for l in lines:\n        if len(l) > 30 or (l[:2] == \"==\" and l[-2:] == \"==\"):\n            cleaned.append(l)\n    text = \"\\n\".join(cleaned)\n\n    # add paragraphs (identified by wiki section title which is always in format \"==Some Title==\")\n    text = text.replace(\"\\n==\", \"\\n\\n\\n==\")\n\n    # remove empty paragrahps\n    text = re.sub(r\"(==.*==\\n\\n\\n)\", \"\", text)\n    \n    # custom\n    \n    # Remove \"Table of Contents\"\n    text = re.sub(r'Table of Contents', '', text, flags=re.IGNORECASE)  \n    \n    # Remove patterns like 4\\x0c\n    text = re.sub(r'\\b\\d*\\x0c\\b', '', text)  \n    \n    # Remove patterns like /n1, and /n\n    text = re.sub(r'(\\\\n|\\n)\\d+|/n', '', text)  # Remove patterns like /n1, /nNUM, and /n\n    \n    # Replace newline characters with spaces that between words\n    text = text.replace('\\n', '')\n    \n    # remove #\\u200b\n    text = text.replace('\\u200b', '')  \n    \n\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-03-07T07:35:20.095229Z","iopub.execute_input":"2024-03-07T07:35:20.096427Z","iopub.status.idle":"2024-03-07T07:35:20.118125Z","shell.execute_reply.started":"2024-03-07T07:35:20.096391Z","shell.execute_reply":"2024-03-07T07:35:20.116573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#all_docs = convert_files_to_docs(dir_path=\"/kaggle/input/ng-machinelearningyearning\", clean_func=clean_text)\n\nall_docs = convert_files_to_docs(dir_path=BOOK_DIR,clean_func=clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T07:35:20.119773Z","iopub.execute_input":"2024-03-07T07:35:20.120153Z","iopub.status.idle":"2024-03-07T07:35:30.639195Z","shell.execute_reply.started":"2024-03-07T07:35:20.120094Z","shell.execute_reply":"2024-03-07T07:35:30.637427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(all_docs))","metadata":{"execution":{"iopub.status.busy":"2024-03-07T07:35:30.641195Z","iopub.execute_input":"2024-03-07T07:35:30.641982Z","iopub.status.idle":"2024-03-07T07:35:30.649385Z","shell.execute_reply.started":"2024-03-07T07:35:30.64194Z","shell.execute_reply":"2024-03-07T07:35:30.647511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- split to chunks and some more cleaning","metadata":{}},{"cell_type":"code","source":"processor = PreProcessor(\n    clean_empty_lines=True,\n    clean_whitespace=True,\n    clean_header_footer=True,\n    remove_substrings=None,\n    split_by=\"word\",\n    split_length=100, # suitable for the dense vector\n    split_respect_sentence_boundary=True,\n    split_overlap= 4,\n    max_chars_check = 10_000,\n    progress_bar = True\n)\ndocs = processor.process(all_docs)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T07:35:30.651245Z","iopub.execute_input":"2024-03-07T07:35:30.651589Z","iopub.status.idle":"2024-03-07T07:35:35.093321Z","shell.execute_reply.started":"2024-03-07T07:35:30.65156Z","shell.execute_reply":"2024-03-07T07:35:35.092169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(docs)}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-07T07:35:35.094818Z","iopub.execute_input":"2024-03-07T07:35:35.09609Z","iopub.status.idle":"2024-03-07T07:35:35.102748Z","shell.execute_reply.started":"2024-03-07T07:35:35.096047Z","shell.execute_reply":"2024-03-07T07:35:35.101293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# look at example\nsample = docs[5]\nsample\n# 4\\x0c\n# assume\\nthat","metadata":{"execution":{"iopub.status.busy":"2024-03-07T07:35:35.104736Z","iopub.execute_input":"2024-03-07T07:35:35.105608Z","iopub.status.idle":"2024-03-07T07:35:35.158167Z","shell.execute_reply.started":"2024-03-07T07:35:35.105562Z","shell.execute_reply":"2024-03-07T07:35:35.156825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  retrieval\n    - using FAISS DB to work more with embedings","metadata":{}},{"cell_type":"code","source":"document_store = FAISSDocumentStore(sql_url=\"sqlite:///\", faiss_index_factory_str=\"Flat\")\n\n# write the docs to the DB\ndocument_store.write_documents(docs)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T07:35:35.162755Z","iopub.execute_input":"2024-03-07T07:35:35.16316Z","iopub.status.idle":"2024-03-07T07:36:00.431189Z","shell.execute_reply.started":"2024-03-07T07:35:35.163119Z","shell.execute_reply":"2024-03-07T07:36:00.4284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retriever = EmbeddingRetriever(\n    document_store=document_store, \n    embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\",\n    max_seq_len = 256,\n    batch_size = 32,\n    top_k = 10\n)\n# Important:\n# Now that we initialized the Retriever, we need to call update_embeddings() to iterate over all\n# previously indexed documents and update their embedding representation.\n# While this can be a time consuming operation (depending on the corpus size), it only needs to be done once.\n# At query time, we only need to embed the query and compare it to the existing document embeddings, which is very fast.\ndocument_store.update_embeddings(retriever)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-07T07:36:00.43304Z","iopub.execute_input":"2024-03-07T07:36:00.434001Z","iopub.status.idle":"2024-03-07T08:15:27.561441Z","shell.execute_reply.started":"2024-03-07T07:36:00.433961Z","shell.execute_reply":"2024-03-07T08:15:27.559918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generative","metadata":{}},{"cell_type":"code","source":"model_name = 'google/flan-t5-base' #'facebook/bart-large-cnn'\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name,torch_dtype = torch.bfloat16)\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-07T08:15:27.563603Z","iopub.execute_input":"2024-03-07T08:15:27.56414Z","iopub.status.idle":"2024-03-07T08:15:38.294675Z","shell.execute_reply.started":"2024-03-07T08:15:27.564074Z","shell.execute_reply":"2024-03-07T08:15:38.292533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RAG Integration","metadata":{}},{"cell_type":"code","source":"# pipeline\n\n\ndef model_predict(model,prompt):\n    \n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n    outputs = model.generate(input_ids=input_ids)#, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n\ndef RAG_pipeline(question):\n\n    pipeline = Pipeline()\n    pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n    pipeline.add_node(component=TopPSampler(top_p=0.90), name=\"Sampler\", inputs=[\"Retriever\"])\n    pipeline.add_node(component=LostInTheMiddleRanker(1024), name=\"LostInTheMiddleRanker\", inputs=[\"Sampler\"])\n    return pipeline.run(query=question)\n    \n    \nprompts = []    \n    \ndef RAG_Predict(model, question):\n \n    result = RAG_pipeline(question)\n    \n    context = \"\"\n    for d in result['documents']:\n        context += d.content\n    context\n    \n    prompt = f\"\"\"Answer the following question based on the context: \\n Question: {question} \\n Context: \\n {context}  \\n Answer: \"\"\"\n    prompts.append(prompt)\n    \n    return model_predict(model,prompt)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-07T08:15:38.300898Z","iopub.execute_input":"2024-03-07T08:15:38.302524Z","iopub.status.idle":"2024-03-07T08:15:38.321183Z","shell.execute_reply.started":"2024-03-07T08:15:38.302466Z","shell.execute_reply":"2024-03-07T08:15:38.319253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## test zero shot","metadata":{}},{"cell_type":"code","source":"# look at the output before finetuning\nquestions = [\n    \"What is machine learning?\",\n    \"What is the difference between supervised and unsupervised learning?\",\n    \"What is a neural network?\",\n    \"What is the purpose of activation functions in neural networks?\",\n    \"What is overfitting in machine learning?\",\n    \"What is gradient descent?\",\n    \"What is the difference between classification and regression in machine learning?\",\n    \"What is a convolutional neural network (CNN) used for?\",\n    \"What is transfer learning in deep learning?\",\n    \"What is the purpose of regularization techniques in machine learning?\"\n]","metadata":{"execution":{"iopub.status.busy":"2024-03-07T08:15:38.322951Z","iopub.execute_input":"2024-03-07T08:15:38.323921Z","iopub.status.idle":"2024-03-07T08:15:38.963231Z","shell.execute_reply.started":"2024-03-07T08:15:38.323885Z","shell.execute_reply":"2024-03-07T08:15:38.961149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10 questions\n\n# taking answers\nanswers = []\n\nfor question in questions:\n    \n    answer = RAG_Predict(model,question)\n    answers.append(answer)\n    \n # df   \nbase_answers = pd.DataFrame({'questions' : questions, 'answers' : answers})\n\npd.set_option('display.max_colwidth', None)\nbase_answers","metadata":{"execution":{"iopub.status.busy":"2024-03-07T08:15:38.96605Z","iopub.execute_input":"2024-03-07T08:15:38.967344Z","iopub.status.idle":"2024-03-07T08:24:11.362923Z","shell.execute_reply.started":"2024-03-07T08:15:38.967304Z","shell.execute_reply":"2024-03-07T08:24:11.361195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## evaluate:","metadata":{}},{"cell_type":"code","source":"# chat gpt answers -> i used the same prompt with the same context\n# to evaluate with rouge and semantic simalarty\n\nchatGPT_answers = [\n    \"Machine learning is about designing algorithms that automatically extract valuable information from data. It emphasizes automatic extraction of meaningful information from data without much domain-specific expertise, aiming for general-purpose methodologies applicable to various datasets.\",\n    \"Supervised learning involves observing several examples of a random vector x and an associated value or vector y, and learning to predict y from x. In contrast, unsupervised learning involves observing several examples of a random vector x without associated values and attempting to implicitly or explicitly learn the probability distribution p(x) or some interesting properties of that distribution.\",\n    \"Neural networks, specifically feedforward networks, are composed of interconnected functions represented by a directed acyclic graph. They are organized into layers, with each layer being a function of the preceding one. Hidden unit design and determining the architecture are key considerations in neural network design.\",\n    \"The activation function in neural networks, such as the rectified linear unit (ReLU), is applied element-wise to the output of linear transformations. It introduces nonlinearity to the network, enabling it to learn complex patterns and relationships in the data.\",\n    \"Overfitting in machine learning occurs when a model memorizes the training data excessively, leading to poor performance on unseen data (test set). It happens when the model has high capacity and fits the noise in the training data rather than capturing the underlying patterns.\",\n    \"Gradient descent is a first-order optimization algorithm used to find a local minimum of a function by taking steps proportional to the negative gradient of the function at the current point. Stochastic gradient descent is an extension that uses a subset of training examples in each iteration to approximate the gradient.\",\n    \"Classification involves predicting discrete labels or categories for input data, while regression involves predicting continuous values. In classification, the labels are typically integers, whereas in regression, the labels are real-valued.\",\n    \"Convolutional neural networks (CNNs) are specialized neural networks for processing data with a known grid-like topology, such as time-series or image data. They utilize convolution, a specialized kind of linear operation, to extract features from the input data efficiently.\",\n    \"Transfer learning in deep learning involves leveraging knowledge learned from one task or domain to improve performance on another related task or domain. It can reduce the amount of labeled data needed for training and enhance generalization to new tasks.\",\n    \"Regularization techniques in machine learning are designed to reduce generalization error (error on unseen data) without significantly increasing training error. They include adding constraints or penalties on model parameters to prevent overfitting and improve model performance on unseen data. Regularization is crucial for controlling the complexity of models and preventing overfitting.\"\n]\n\n\n# rouge function\n\ndef eval_rouge(refs,preds):\n    \n    result = metric.compute(predictions=preds, references=refs, use_stemmer=True, use_aggregator=False)\n    \n    return result['rouge1'],np.mean(result['rouge1'])\nprint(eval_rouge(chatGPT_answers,answers))","metadata":{"execution":{"iopub.status.busy":"2024-03-07T08:47:22.200544Z","iopub.execute_input":"2024-03-07T08:47:22.201032Z","iopub.status.idle":"2024-03-07T08:47:22.313861Z","shell.execute_reply.started":"2024-03-07T08:47:22.200999Z","shell.execute_reply":"2024-03-07T08:47:22.312452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# similarty \nfrom sentence_transformers import SentenceTransformer, util\n\ndef cos_sim(refs,preds):\n    \n\n    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n    # Encode all sentences\n    refs_embd = model.encode(refs)\n    preds_embd = model.encode(preds)\n\n    # Compute cosine similarity between all pairs\n    cos_sim = util.cos_sim(refs_embd, preds_embd)\n    \n    return cos_sim\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-07T08:52:20.634497Z","iopub.execute_input":"2024-03-07T08:52:20.634983Z","iopub.status.idle":"2024-03-07T08:52:20.645459Z","shell.execute_reply.started":"2024-03-07T08:52:20.634945Z","shell.execute_reply":"2024-03-07T08:52:20.643552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#instructed model\n\n# similarity\nsim = []\nfor r,q in zip(chatGPT_answers,answers):\n    sim.append(float(cos_sim(r,q)[0, 0]))\nprint(f\" the average of the similarity =  {np.mean(sim)}\")\n\n\nrouges,ave = eval_rouge(chatGPT_answers,answers)\n\nprint(f\" the average of the rouge scores is  =  {ave} \\n the rouge scores = {rouges}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-07T09:16:16.792232Z","iopub.execute_input":"2024-03-07T09:16:16.792783Z","iopub.status.idle":"2024-03-07T09:16:26.827833Z","shell.execute_reply.started":"2024-03-07T09:16:16.792745Z","shell.execute_reply":"2024-03-07T09:16:26.826211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LoRa Fine tune","metadata":{}},{"cell_type":"markdown","source":"[fine-tune notebook](https://www.kaggle.com/code/tarekyahia/fine-tune-flan-t5-question-answer-squad/notebook)","metadata":{}},{"cell_type":"code","source":"# load\n\npeft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n\npeft_model = PeftModel.from_pretrained(peft_model_base, \n                                       '/kaggle/input/peft-flan-t5/checkpoint-29982', \n                                       torch_dtype=torch.bfloat16,\n                                       is_trainable=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T09:11:32.339883Z","iopub.execute_input":"2024-03-07T09:11:32.340445Z","iopub.status.idle":"2024-03-07T09:11:37.020838Z","shell.execute_reply.started":"2024-03-07T09:11:32.340408Z","shell.execute_reply":"2024-03-07T09:11:37.019245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answers_fine = []\n\nfor question in questions:\n    answer = RAG_Predict(peft_model,question)\n    answers_fine.append(answer)\n    \n# 10 questions\n\nfine_answers = pd.DataFrame({'questions' : questions, 'answers' : answers_fine})\n\nfine_answers","metadata":{"execution":{"iopub.status.busy":"2024-03-07T08:26:59.377873Z","iopub.execute_input":"2024-03-07T08:26:59.378679Z","iopub.status.idle":"2024-03-07T08:35:38.281024Z","shell.execute_reply.started":"2024-03-07T08:26:59.37864Z","shell.execute_reply":"2024-03-07T08:35:38.279475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(eval_rouge(chatGPT_answers,answers_fine))","metadata":{"execution":{"iopub.status.busy":"2024-03-07T08:48:02.541665Z","iopub.execute_input":"2024-03-07T08:48:02.542089Z","iopub.status.idle":"2024-03-07T08:48:02.600264Z","shell.execute_reply.started":"2024-03-07T08:48:02.542059Z","shell.execute_reply":"2024-03-07T08:48:02.598682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fine tuned model\n\n# similarity\nsim = []\nfor r,q in zip(chatGPT_answers,answers_fine):\n    sim.append(float(cos_sim(r,q)[0, 0]))\nprint(f\" the average of the similarity =  {np.mean(sim)}\")\n\n\nrouges,ave = eval_rouge(chatGPT_answers,answers)\n\nprint(f\" the average of the rouge scores is  =  {ave} \\n the rouge scores = {rouges}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-07T09:01:44.132334Z","iopub.execute_input":"2024-03-07T09:01:44.132817Z","iopub.status.idle":"2024-03-07T09:01:54.273765Z","shell.execute_reply.started":"2024-03-07T09:01:44.132784Z","shell.execute_reply":"2024-03-07T09:01:54.272157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> the peft and zero shot instructed model get the same resoults.! the fine tune has no improvements i think if the dataset is very related then will do some improvement.","metadata":{}}]}